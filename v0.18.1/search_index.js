var documenterSearchIndex = {"docs":
[{"location":"generated/examples/1-mirt/","page":"MIRT overview","title":"MIRT overview","text":"EditURL = \"../../../lit/examples/1-mirt.jl\"","category":"page"},{"location":"generated/examples/1-mirt/#1-mirt","page":"MIRT overview","title":"MIRT overview","text":"","category":"section"},{"location":"generated/examples/1-mirt/","page":"MIRT overview","title":"MIRT overview","text":"The Julia package MIRT.jl provides tools for performing image reconstruction and solving related inverse problems.","category":"page"},{"location":"generated/examples/1-mirt/","page":"MIRT overview","title":"MIRT overview","text":"For more tools and more examples, see JuliaImageRecon","category":"page"},{"location":"generated/examples/1-mirt/","page":"MIRT overview","title":"MIRT overview","text":"","category":"page"},{"location":"generated/examples/1-mirt/","page":"MIRT overview","title":"MIRT overview","text":"This page was generated using Literate.jl.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"EditURL = \"../../../lit/examples/2-nufft.jl\"","category":"page"},{"location":"generated/examples/2-nufft/#2-nufft","page":"NUFFT","title":"NUFFT","text":"","category":"section"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"Examples illustrating the nufft methods in the Julia package MIRT.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"The nufft functions in this package are wrappers around NFFT.jl.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"The plots on this page are simply sanity checks about of the approximation error for that package and they help verify the correctness of the wrapper.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"This page comes from a single Julia file: 2-nufft.jl.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"You can access the source code for such Julia documentation using the 'Edit on GitHub' link in the top right. You can view the corresponding notebook in nbviewer here: 2-nufft.ipynb, or open it in binder here: 2-nufft.ipynb.","category":"page"},{"location":"generated/examples/2-nufft/#Setup","page":"NUFFT","title":"Setup","text":"","category":"section"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"Packages needed here.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"using Plots; default(markerstrokecolor = :auto, label=\"\")\nusing MIRTjim: prompt\nusing MIRT: nufft_init, nufft_errors, dtft\nusing InteractiveUtils: versioninfo","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"The following line is helpful when running this file as a script; this way it will prompt user to hit a key after each figure is displayed.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"isinteractive() && prompt(:prompt);\nnothing #hide","category":"page"},{"location":"generated/examples/2-nufft/#1D-example","page":"NUFFT","title":"1D example","text":"","category":"section"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"This code illustrates how to call the NUFFT.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"Ω = range(-1,1,301) * π # digital frequencies (radians/sample)\nN = 16 # # of samples\n(nufft, nufft_adjoint, Anufft) = nufft_init(Ω, N)\nx = randn(ComplexF32, N) # random 1D signal\ny1 = nufft(x) # one way to compute NUFFT\ny2 = Anufft * x # another way to compute NUFFT\n@assert y1 == y2\nyd = dtft(Ω, x) # exact (slow) nonuniform discrete Fourier transform\nmaximum(abs, yd - y1) # worst error for this 1D signal","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"This plot shows that the NUFFT is very close to the exact nonuniform DFT.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"xticks = ([-π,0,π], [\"-π\", \"0\", \"π\"]); xlims = (-π,π); xlabel=\"Ω\"\np1 = plot(ylabel=\"Real part\"; xlabel, xlims, xticks)\nplot!(Ω, real(y1), label=\"real(NUFFT)\", line=:dash)\nplot!(Ω, real(yd), label=\"real(DTFT)\", line=:dot)\np2 = plot(ylabel=\"Imag part\"; xlabel, xlims, xticks)\nplot!(Ω, imag(y1), label=\"imag(NUFFT)\", line=:dash)\nplot!(Ω, imag(yd), label=\"imag(NUFFT)\", line=:dot)\np3 = plot(Ω, real(yd - y1), label=\"real(Error)\"; xlabel, xlims, xticks)\np4 = plot(Ω, imag(yd - y1), label=\"imag(Error)\"; xlabel, xlims, xticks)\nplot(p1, p2, p3, p4)","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"prompt()","category":"page"},{"location":"generated/examples/2-nufft/#Plot-worst-case-errors-vs-N","page":"NUFFT","title":"Plot worst-case errors vs N","text":"","category":"section"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"Plot worst-case error over all frequencies Ω between 0 and 2πN for various N.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"Even for N=512 the error is below 4e-6.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"Nlist = 2 .^ (4:9)\nNlist = [Nlist..., 191, 385] # test odd N values\nerrfunn = N -> maximum(nufft_errors( ; N)[2])\nelist = errfunn.(Nlist)\npn = scatter(Nlist, elist,\n     xtick=Nlist, color=:red, xlabel=\"N\", ylabel=\"error\", yaxis=:log10)","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"prompt()","category":"page"},{"location":"generated/examples/2-nufft/#Plot-error-vs-NFFT-m.","page":"NUFFT","title":"Plot error vs NFFT m.","text":"","category":"section"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"For the default m = 4 the worst-case error is below 4e-6.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"mlist = 3:7\nerrfunm = nfft_m -> maximum(nufft_errors( ; nfft_m)[2])\nworst_m = errfunm.(mlist)\npm = scatter(mlist, worst_m,\n    xlabel=\"m\", ylabel=\"error\", color=:magenta, yaxis=:log10)","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"prompt()","category":"page"},{"location":"generated/examples/2-nufft/#Plot-error-vs-NFFT-sigma.","page":"NUFFT","title":"Plot error vs NFFT sigma.","text":"","category":"section"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"For the default σ = 4 the worst-case error is below 4e-6.","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"slist = [1.5; 2:6] # σ\nerrfuns = nfft_sigma -> maximum(nufft_errors( ; nfft_sigma)[2])\nworst_s = errfuns.(slist)\nps = scatter(slist, worst_s,\n    xlabel=\"σ\", ylabel=\"error\", color=:blue, yaxis=:log10)","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"prompt()","category":"page"},{"location":"generated/examples/2-nufft/#Reproducibility","page":"NUFFT","title":"Reproducibility","text":"","category":"section"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"This page was generated with the following version of Julia:","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"using InteractiveUtils: versioninfo\nio = IOBuffer(); versioninfo(io); split(String(take!(io)), '\\n')","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"And with the following package versions","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"import Pkg; Pkg.status()","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"","category":"page"},{"location":"generated/examples/2-nufft/","page":"NUFFT","title":"NUFFT","text":"This page was generated using Literate.jl.","category":"page"},{"location":"methods/#Methods-list","page":"Methods","title":"Methods list","text":"","category":"section"},{"location":"methods/","page":"Methods","title":"Methods","text":"","category":"page"},{"location":"methods/#Methods-usage","page":"Methods","title":"Methods usage","text":"","category":"section"},{"location":"methods/","page":"Methods","title":"Methods","text":"Modules = [MIRT]","category":"page"},{"location":"methods/#MIRT.MIRT","page":"Methods","title":"MIRT.MIRT","text":"MIRT is the Michigan Image Reconstruction Toolbox\n\n\n\n\n\n","category":"module"},{"location":"methods/#MIRT.LineSearchMM","page":"Methods","title":"MIRT.LineSearchMM","text":"LineSearchMM{...}\n\nMutable struct for MM-based line searches.\n\n\n\n\n\n","category":"type"},{"location":"methods/#MIRT.LineSearchMM-Union{Tuple{Tw}, Tuple{AbstractVector{<:AbstractArray}, AbstractVector{<:AbstractArray}, AbstractVector{<:Function}, AbstractVector{<:Function}}} where Tw<:MIRT.LineSearchMMWork","page":"Methods","title":"MIRT.LineSearchMM","text":"LineSearchMM(gradf, curvf, u, v; α0 ...)\nLineSearchMM(u, v, dot_gradf, dot_curvf; α0 ...)\n\nConstruct iterator for line-search based on majorize-minimize (MM) approach for a general family of 1D cost functions of the form h(α) = sum_j=1^J f_j(u_j + α v_j) where each function f_j(t) has a quadratic majorizer of the form\n\nq_j(ts) = f_j(t) + nabla f_j(s) (t - s) + 12 t - s^2_C_j(s)\n\nwhere C_j() is diagonal matrix of curvatures. (It suffices for each f_j to have a Lipschitz smooth gradient.)\n\nEach function f_j  mathcalX_j  mathbbR where conceptually mathcalX_j  mathbbR^M_j, but we allow more general domains.\n\nThere are two outer constructors (based on the positional arguments):\n\nThe simple way (not type stable) provides\ngradf vector of J functions return gradients of f_1f_J\ncurvf vector of J functions z -> curv(z) that return a scalar or a vector of curvature values for each element of z\nThe fancier way (type stable) provides\ndot_gradf::AbstractVector{<:Function} = make_dot_gradf.(gradf) See make_dot_gradf.\ndot_curvf::AbstractVector{<:Function} = make_dot_curvf.(curvf) See make_dot_curvf.\n\nin\n\nu vector of J arrays u_1u_J (typically vectors)\nv vector of J arrays v_1v_J (typically vectors)\n\nWe require axes(u_j) == axes(v_j) for all j=1J.\n\noption\n\nα0::Real = 0f0 initial guess for step size\nninner::Int = 5 # max number of inner iterations of MM line search\nwork = LineSearchMMWork(u, v, α) pre-allocated work space for u_j+α v_j\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.LineSearchMMWork","page":"Methods","title":"MIRT.LineSearchMMWork","text":"LineSearchMMWork{Tz <: AbstractVector{<:AbstractArray}}\n\nWorkspace for storing z_j = u_j + α v_j in MM-based line search.\n\nIf all of those z_j arrays had the same eltype, then we could save memory by allocating just the longest vector needed. But for Unitful data they could have different eltypes and sizes, which would require a lot of reinterpret and reshape to handle. So we just allocate separate work arrays for each j.\n\n\n\n\n\n","category":"type"},{"location":"methods/#MIRT.Afft-Union{Tuple{AbstractArray{<:Bool, D}}, Tuple{Tw}, Tuple{D}} where {D, Tw<:Number}","page":"Methods","title":"MIRT.Afft","text":"A = Afft(samp::AbstractArray{Bool} ; T, dims, operator, work, ...)\n\nMake a LinearMapAO operator object for (under-sampled) FFT, of type T, using given sampling pattern samp. Especially for compressed sensing MRI with Cartesian sampling.\n\nOption:\n\nT::Type = ComplexF32\ndims = 1:D apply fft/bfft only along these dimensions\nfft_forward::Bool = true Use false to have bfft! in forward model.\noperator::Bool = true set to false to return a LinearMapAM\nwork::AbstractArray work space for in-place fft operations\nremaining arguments are passed to plan_fft\n\nOutput\n\nReturns a LinearMapsAA.LinearMapA[M|O] object.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.Afft-Union{Tuple{Tuple{Vararg{Int64, D}}}, Tuple{Tw}, Tuple{D}, Tuple{Tuple{Vararg{Int64, D}}, Any}} where {D, Tw<:Number}","page":"Methods","title":"MIRT.Afft","text":"A = Afft(xdim::Dims, fdim ; T, operator, unitary, work, ...)\n\nMake a <:LinearMapAX operator object for the FFT of an array of size xdim, along dimensions fdim, of type T.\n\nIn:\n\nxdim::Dims{D} array size\nfdim = 1:D apply fft/bfft only along these dimensions\n\nOption:\n\nT::Type = ComplexF32\noperator::Bool = true return a LinearMapAO set to false to return a LinearMapAM\nunitary::Bool = false set to true for unitary DFT\nwork::AbstractArray work space for in-place fft operations\nremaining arguments are passed to plan_fft\n\nOutput\n\nReturns a LinearMapsAA.LinearMapA[M|O] object.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.Anufft-Tuple{AbstractArray{<:Real}, Int64}","page":"Methods","title":"MIRT.Anufft","text":"Anufft(ω, N ; kwargs ...)\n\nMake a LinearMapAO object of size length(ω) × prod(N). See nufft_init for options.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.Aodwt-Tuple{Tuple{Vararg{Int64, N}} where N}","page":"Methods","title":"MIRT.Aodwt","text":"A, levels, mfun = Aodwt(dims ; level::Int=3, wt=wavelet(WT.haar))\n\nCreate orthogonal discrete wavelet transform (ODWT) LinearMapAA\n\nin\n\ndims::Dims tuple of dimensions\n\noption\n\nlevel::Int # of levels; default 3\nwt wavelet transform type (see Wavelets package); default Haar\noperator::Bool=true default to LinearMapAO\nT::Type : Float32 by default; use ComplexF32 if needed\n\nout\n\nA a LinearMapAX object\nscales array of size dims showing the scale of each coefficient\n\nwhich is useful when imposing scale-dependent regularization\n\nmfun convenience function for A*X when X is a Matrix or Array (not vector)\n\n2019-02-23 Jeff Fessler, University of Michigan\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.Asense-Union{Tuple{Tw}, Tuple{D}, Tuple{AbstractArray{<:Bool, D}, Vector{<:AbstractArray{<:Number}}}} where {D, Tw<:Number}","page":"Methods","title":"MIRT.Asense","text":"Asense(samp, smaps; T)\n\nConstruct a MRI encoding operator model for D-dimensional Cartesian sampling pattern samp and coil sensitivity maps smaps.\n\nThe input smaps can either be a D+1 dimensional array of size (size(samp)..., ncoil), or a Vector of ncoil arrays of size size(samp).\n\nInput\n\nsamp::AbstractArray{<:Bool} D-dimensional sampling pattern.\nsmaps::Vector{<:AbstractArray{<:Number}} or AbstractArray{<:Number}\n\nOption\n\nT::Type = ComplexF32\ndims = 1:D apply fft/bfft only along these dimensions\nfft_forward::Bool = true Use false to have bfft! in forward model.\nunitary::Bool = false set to true for unitary DFT\nremaining arguments are passed to plan_fft\n\nOutput\n\nReturns a LinearMapsAA.LinearMapAO object.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT._show_struct-Tuple{IO, MIME{Symbol(\"text/plain\")}, Any}","page":"Methods","title":"MIRT._show_struct","text":"_show_struct(io::IO, ::MIME\"text/plain\", st::Any)\n\nInformative way to show fields of a struct (composite type).\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.caller_name-Tuple{}","page":"Methods","title":"MIRT.caller_name","text":"caller_name() or caller_name(;level=4)\n\nReturn \"filename line fun():\" as a string to describe where this function was called.\n\nStack levels:\n\n1: #caller_name\n2: caller_name()\n3: function that invoked caller()\n4: the calling function we want to return\n\nHence the default level is 4, but we increment it by one in case user says @show caller_name() in which case stack[3] is a macro expansion.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diff_adj-Union{Tuple{D}, Tuple{AbstractVector{<:Number}, Tuple{Vararg{Int64, D}}}} where D","page":"Methods","title":"MIRT.diff_adj","text":"Z = diff_adj(dx, N::Dims{D} ; dims = 1:D)\n\nAdjoint of finite differences of arrays along one or more dimensions. By default performs the same operations as vec(Z) = (I_N_d otimes cdots otimes D_N_1) dots (D_N_d otimes cdots otimes I_N_1) * d where D_N denotes the N-1 × N 1D finite difference matrix and ⊗ denotes the Kronecker product, but does it efficiently without using spdiagm (or any SparseArrays function).\n\nin\n\ndx vector of typical length N_d*...*(N_1-1) + ... + (N_d-1)*...*N_1\nN::Dims desired output size\n\noption\n\ndims dimension(s) for performing adjoint finite differences; default 1:ndims(X)\n\nout\n\nZ N_1 × ... × N_d array by default\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diff_forw-Union{Tuple{AbstractArray{<:Number, D}}, Tuple{D}} where D","page":"Methods","title":"MIRT.diff_forw","text":"d = diff_forw(X ; dims = 1:ndims(X))\n\nFinite differences along one or more dimensions of an array, e.g., for anisotropic TV regularization.\n\nBy default performs the same operations as d = (I_N_d otimes cdots otimes D_N_1) dots (D_N_d otimes cdots otimes I_N_1) vec(X) where D_N denotes the N-1 × N 1D finite difference matrix and ⊗ denotes the Kronecker product, but does it efficiently without using spdiagm (or any SparseArrays function).\n\nInput dimension N must exceed 1 for each dimension specified by dims.\n\nin\n\nX N_1 × ... × N_d array (typically an N-D image).\n\noption\n\ndims dimension(s) for performing finite differences; default 1:ndims(X)\n\nmust have unique elements and be a nonempty subset of 1:ndims(X)\n\nout\n\nd vector of default length N_d*...*(N_1-1) + ... + (N_d-1)*...*N_1\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diff_map-Union{Tuple{Tuple{Vararg{Int64, D}}}, Tuple{D}} where D","page":"Methods","title":"MIRT.diff_map","text":"T = diff_map(N::Dims{D} ; dims = 1:D)\n\nin\n\nN::Dims image size\n\nout\n\nT LinearMapAA object for computing finite differences via T*x\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diffl!-Union{Tuple{Nx}, Tuple{Ng}, Tuple{Tx}, Tuple{Tg}, Tuple{AbstractArray{Tg, Ng}, AbstractArray{Tx, Nx}, AbstractVector{Int64}}} where {Tg, Tx, Ng, Nx}","page":"Methods","title":"MIRT.diffl!","text":"diffl!(g::AbstractArray, x::AbstractArray, dims::AbstractVector{Int} ; ...)\n\nWhen x is a N-dimensional array, the ith slice of the g array (along its last dimension) is the diffl! of x along dims[i]. This is useful for total variation (TV) and other regularizers that need finite differences along multiple dimensions.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diffl!-Union{Tuple{N}, Tuple{Tx}, Tuple{Tg}, Tuple{AbstractArray{Tg, N}, AbstractArray{Tx, N}, Int64}} where {Tg, Tx, N}","page":"Methods","title":"MIRT.diffl!","text":"diffl!(g::AbstractArray, x::AbstractArray, dim::Int ; ...)\n\nApply left finite difference operator to input array x, storing the result \"in-place\" in pre-allocated output array g. (The letter g is mnemonic for \"gradient\".)\n\nArrays g and x must have the same size, and cannot alias. By default, the \"first\" elements of g are zero for dimension dim. The default is dim=1.\n\nOption:\n\nadd::Bool = false use x[i] + x[i-1] instead of x[i] - x[i-1] (useful for certain diagonal majorizers).\nedge::Symbol = :zero set the first elements of dimension dim to 0\nChoose edge=:circ to use circulant (aka periodic) boundary conditions.\nChoose edge=:none to leave the first elements untouched.\n\nExample\n\njulia> x = [2, 6, 7]; g = similar(x); diffl!(g, x)\n3-element Vector{Int64}:\n 0\n 4\n 1\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diffl-Tuple{AbstractArray, AbstractVector{Int64}}","page":"Methods","title":"MIRT.diffl","text":"g = diffl(x::AbstractArray, dims::AbstractVector{Int} ; ...)\n\nAllocating version of diffl! for dims\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diffl-Tuple{AbstractArray, Int64}","page":"Methods","title":"MIRT.diffl","text":"g = diffl(x::AbstractArray, dim::Int ; ...)\n\nAllocating version of diffl! along dim\n\nExample\n\njulia> x = [1,2] .+ [10 30 70]; g = diffl(x, 2)\n2×3 Matrix{Int64}:\n 0  20  40\n 0  20  40\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diffl-Tuple{AbstractArray}","page":"Methods","title":"MIRT.diffl","text":"g = diffl(x::AbstractArray ; ...)\n\nAllocating version of diffl! along dim=1\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diffl_adj!-Union{Tuple{Ng}, Tuple{Nz}, Tuple{Tg}, Tuple{Tz}, Tuple{AbstractArray{Tz, Nz}, AbstractArray{Tg, Ng}, AbstractVector{Int64}}} where {Tz, Tg, Nz, Ng}","page":"Methods","title":"MIRT.diffl_adj!","text":"diffl_adj!(z::AbstractArray, g::AbstractArray, dims::AbstractVector{Int} ; ...)\n\nAdjoint of diffl! for multiple dimensions dims. Here g must have one more dimension than z.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diffl_adj!-Union{Tuple{N}, Tuple{Tg}, Tuple{Tz}, Tuple{AbstractArray{Tz, N}, AbstractArray{Tg, N}, Int64}} where {Tz, Tg, N}","page":"Methods","title":"MIRT.diffl_adj!","text":"diffl_adj!(z, g, dim::Int ; ...)\n\nAdjoint of left finite difference diffl!, in-place. Arrays z and g must be same size. See diffl_adj for details.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diffl_adj-Tuple{AbstractArray, Int64}","page":"Methods","title":"MIRT.diffl_adj","text":"z = diffl_adj(g::AbstractArray, dim::Int ; ...)\n\nAllocating version of diffl_adj! along dim.\n\nExample\n\njulia> g = ones(Int,2,3); z = diffl_adj(g, 2)\n2×3 Matrix{Int64}:\n -1  0  1\n -1  0  1\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diffl_adj-Tuple{AbstractArray}","page":"Methods","title":"MIRT.diffl_adj","text":"z = diffl_adj(g::AbstractArray ; ...)\n\nAllocating version of diffl_adj! along dim=1.\n\nExample\n\njulia> g = [0, 2, 5]; z = diffl_adj(g)\n3-element Vector{Int64}:\n -2\n -3\n  5\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diffl_adj-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T, N}, AbstractVector{Int64}}} where {T, N}","page":"Methods","title":"MIRT.diffl_adj","text":"z = diffl_adj(g::AbstractArray, dims::AbstractVector{Int} ; ...)\n\nAllocating version of diffl_adj! for dims.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.diffl_map-Union{Tuple{D}, Tuple{Tuple{Vararg{Int64, D}}, AbstractVector{Int64}}} where D","page":"Methods","title":"MIRT.diffl_map","text":"T = diffl_map(N::Dims{D}, dims::AbstractVector{Int} ; kwargs...)\nT = diffl_map(N::Dims{D}, dim::Int ; kwargs...)\n\nin\n\nN::Dims image size\n\noptions: see diffl!\n\nT::Type for LinearMapAA, default Float32\noperator::Bool = true use false for LinearMapAM\n\nout\n\nT LinearMapAA object for computing finite differences via T*x\n\nusing diffl! and diffl_adj!\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.downsample1-Tuple{AbstractVector{<:Number}, Int64}","page":"Methods","title":"MIRT.downsample1","text":"y = downsample1(x, down ; warn=true)\n\nDownsample 1D vector by factor down.\n\nin\n\nx [n1]\ndown::Int downsampling factor\n\noption\n\nwarn::Bool warn if noninteger multiple; default isinteractive()\n\nout\n\ny [n1/down]\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.downsample2-Tuple{AbstractMatrix{<:Number}, Tuple{Int64, Int64}}","page":"Methods","title":"MIRT.downsample2","text":"y = downsample2(x, down ; warn=true, T)\n\nDownsample by averaging by integer factors.\n\nin\n\nx [nx ny]\ndown can be a scalar (same factor for both dimensions) or a NTuple{2,Int}\n\noption\n\nwarn::Bool warn if noninteger multiple; default isinteractive()\nT::Type specify output eltype; default eltype(x[1] / down[1])\n\nout\n\ny [nx/down ny/down]\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.downsample3-Tuple{AbstractArray{<:Number, 3}, Tuple{Int64, Int64, Int64}}","page":"Methods","title":"MIRT.downsample3","text":"y = downsample3(x, down ; warn=true, T)\n\nDownsample by averaging by integer factors.\n\nin\n\nx (nx,ny,nz)\ndown can be a scalar (same factor for all dimensions) or a NTuple{3,Int}\n\noption\n\nwarn::Bool warn if noninteger multiple; default true\nT::Type specify output eltype; default eltype(x[1] / down[1])\n\nout\n\ny (nx/down,ny/down,nz/down)\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.downsample_dim1-Tuple{AbstractArray{<:Number}, Int64}","page":"Methods","title":"MIRT.downsample_dim1","text":"y = downsample_dim1(x, down ; warn::Bool)\n\nDown-sample x by factor down along first dimension by averaging.\n\nin\n\nx [n1 (Nd)]\ndown::Int downsampling factor\n\noption\n\nwarn::Bool warn if non-integer multiple; default isinteractive()\n\nout\n\ny [n1÷down (Nd)]\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.dtft-Tuple{AbstractMatrix{<:Real}, AbstractMatrix{<:Number}}","page":"Methods","title":"MIRT.dtft","text":"X = dtft(w, x ; n_shift=?)\n\nmulti-dimensional DTFT (DSFT)\n\nXm = sum_n=0^N-1 xn exp(-i wm (n - n_shift)) m=1M where here n is a CartesianIndex\n\nin\n\nw::AbstractMatrix{<:Real} (M,D) frequency locations (\"units\" radians/sample)\nx::AbstractArray{<:Number} [(Nd)] D-dimensional signal\n\noption\n\nn_shift::AbstractVector{<:Real} often is N/2; default zeros(D)\n\nout\n\nX::AbstractVector{ComplexF64} (M) DTFT\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.dtft-Tuple{AbstractVector{<:Real}, AbstractVector{<:Number}}","page":"Methods","title":"MIRT.dtft","text":"X = dtft(w, x ; n_shift=?)\n\n1D DTFT\n\nXm = sum_n=0^N-1 xn exp(-i wm (n - n_shift)) m=1M\n\nin\n\nw::AbstractVector{<:Real} (M) frequency locations (\"units\" radians/sample)\nx::AbstractVector{<:Number} (N) 1D signal\n\noption\n\nn_shift::Real often is N/2; default 0\n\nout\n\nX::AbstractVector{ComplexF64} [M] DTFT\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.dtft_adj-Tuple{AbstractMatrix{<:Real}, AbstractVector{<:Number}, Tuple{Vararg{Int64, N}} where N}","page":"Methods","title":"MIRT.dtft_adj","text":"x = dtft_adj(w, X, N ; n_shift=?)\n\nadjoint for multi-dimensional DTFT (DSFT)\n\nxn = sum_m=1^M Xm exp(i wm (n - n_shift)) n=0N-1 where here n is a CartesianIndex\n\nin\n\nX::AbstractVector{ComplexF64} (M) DTFT\nw::AbstractMatrix{<:Real} (M,D) frequency locations (\"units\" radians/sample)\nN::Dims (D) dimensions of signal x\n\noption\n\nn_shift::AbstractVector{<:Real} often is N/2; default zeros(D)\nT::Type default (eltype(w) == Float64) ? ComplexF64 : ComplexF32\n\nout\n\nx::AbstractArray{<:Number} [(N)] D-dimensional signal\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.dtft_adj-Tuple{AbstractVector{<:Real}, AbstractVector{<:Number}, Int64}","page":"Methods","title":"MIRT.dtft_adj","text":"x = dtft_adj(w, X, N ; n_shift=?)\n\nadjoint for 1D DTFT\n\nxn = sum_m=1^M Xm exp(i wm (n - n_shift)) n=0N-1\n\nThis is the adjoint (transpose) of dtft, not an inverse DTFT.\n\nin\n\nw::AbstractVector{<:Real} (M) frequency locations (\"units\" radians/sample)\nX::AbstractVector{ComplexF64} (M) spectrum values\nN::Int size of signal x\n\noption\n\nn_shift::Real often is N/2; default 0\nT::Type output data type; default ComplexF64\n\nout\n\nx::AbstractVector{<:Number} (N) signal\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.dtft_init-Tuple{AbstractMatrix{<:Real}, Tuple{Vararg{Int64, N}} where N}","page":"Methods","title":"MIRT.dtft_init","text":"d = dtft_init(w, N ; n_shift=?)\n\nfor multi-dimensional DTFT (DSFT)\n\nin\n\nw::AbstractMatrix{<:Real} (M,D) frequency locations (\"units\" radians/sample)\nN::Dims [D] dimensions of signal x\n\noption\n\nn_shift::AbstractVector{<:Real} often is N/2; default zeros(D)\nT::Type default ComplexF64 for testing NUFFT accuracy\n\nout\n\nd::NamedTuple with fields   dtft = x -> dtft(x), adjoint = y -> dtft_adj(y), A=LinearMapAO\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.dtft_init-Tuple{AbstractVector{<:Real}, Int64}","page":"Methods","title":"MIRT.dtft_init","text":"d = dtft_init(w, N ; n_shift=?)\n\nFor 1D DTFT\n\nin\n\nw::AbstractVector{<:Real} (M) frequency locations (\"units\" radians/sample)\nN::Int size of signal x\n\noption\n\nn_shift::Real often is N/2; default 0\nT::Type default ComplexF64 for testing NUFFT accuracy\n\nout\n\nd::NamedTuple with fields   dtft = x -> dtft(x), adjoint = y -> dtft_adj(y), A=LinearMapAO\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.embed!-Union{Tuple{D}, Tuple{T}, Tuple{AbstractArray{T, D}, AbstractVector{<:Number}, AbstractArray{Bool, D}}} where {T, D}","page":"Methods","title":"MIRT.embed!","text":"embed!(array, v, mask ; filler=0)\n\nembed vector v of length sum(mask) into elements of array where mask is true, setting the remaining elements to filler (default 0).\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.embed-Tuple{AbstractMatrix{<:Number}, AbstractArray{Bool}}","page":"Methods","title":"MIRT.embed","text":"array = embed(matrix::AbstractMatrix{<:Number}, mask::AbstractArray{Bool})\n\nEmbed each column of matrix into mask then cat along next dimension In:\n\nmatrix [sum(mask) L]\nmask [(N)]\n\nOut:\n\narray [(N) L]\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.embed-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractArray{Bool}}} where T<:Number","page":"Methods","title":"MIRT.embed","text":"array = embed(v, mask ; filler=0)\n\nembed vector v of length sum(mask) into elements of an array where mask is true; see embed!.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.eql_root-Tuple{Real, Real, Real}","page":"Methods","title":"MIRT.eql_root","text":"x = eql_root(a,b,c)\n\nNumerically stable method for computing the positive root of the quadratic polynomial -ax^2 - 2bx + c, a >= 0. Assumes solvable equations; will throw otherwise.\n\nin\n\na The negative of the x^2 term. Must be positive.\nb Half the negative of the x term.\nc The constant term.\n\nout\n\nx The positive root that satisfies 0 = -ax^2 - 2bx + c.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.exp_mult-Tuple{Any, AbstractVector{<:Number}, AbstractVector{<:Number}}","page":"Methods","title":"MIRT.exp_mult","text":"D = exp_mult(A, u, v ; warnboth)\n\nMemory efficient and fast implementation of D = A' * exp(-u * v^T) that is useful for B0-field-corrected MRI image reconstruction.\n\nin\n\nA [N L] matrix\nu [N] vector\nv [M] vector\nwarnboth warn if both u and v are complex; default: true\n\nout\n\nD [L M] complex vector: D = A' * exp(-u * v^T)\n\nD_lm = sum_n A_nl^* exp(-u_n v_m)\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.exp_xform-Tuple{AbstractMatrix{<:Number}, AbstractMatrix{<:Number}, AbstractMatrix{<:Number}}","page":"Methods","title":"MIRT.exp_xform","text":"exp_xform(x, u, v ; mode::Symbol = :matrix)\n\nin\n\nx [N L] possibly complex vector(s)\nu [D N] possibly complex vectors\nv [D M] possibly complex vectors\nmode::Symbol :matrix (default) | :element | :row | :column\n\nout\n\ny [M L] typically complex vector\n\ny[m,l] = sum_n x[n,l] exp(-sum(u[:,n] .* v[:,m]))\n\nIterates through subsets of the ML matrix designated by :mode (i.e. row, column, element, or just computing the entire matrix) This is the 'slow' 'exact' transform model for MRI.\n\nOutput type will depend on input types.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.genkspace-NTuple{8, Any}","page":"Methods","title":"MIRT.genkspace","text":"genkspace\n\nGenerate the proper length of k-space trajectory.\n\nIt linearly interpolates the output of genspiral to the correct length() & takes care of the rotations for the interleaves.\n\nld is the length of the data\nnint is the number of interleaves\n\nBrad Sutton; University of Michigan\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.genspi-Tuple{Any, Any}","page":"Methods","title":"MIRT.genspi","text":"Gx, Gy, kx, ky, sx, sy, gts = genspi(...)\n\nThis is translation of C code from scanner: exactly what is played out to gradients at 4us.\n\nMulti-shot spiral design uses Duyn's approximate slewrate limited design augmented with archimedean gmax limit\n\nin [args]\n\nD = FOV; cm\nN = matrix size()\nTmax = longest acquisition allowed; s\ndts = output sample spacing; s\ngtype = trajectory type()\n\noption [CVs]\n\nnl = number of interleaves\ngamp = design grad max; G/cm\ngslew = design slew rate; mT/m/ms\nnramp = number of rampdown points; default 0\n\nout\n\nGx; Gy\n\ntime is in sec()\n\nrev 0 12/26/98    original\nrev 1 4/15/99    little better calc of ts\n\nBorrowed from Doug Noll; Univ. of Michigan. Modified to take more input cv's.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.getindex!-Union{Tuple{D}, Tuple{T}, Tuple{AbstractVector, AbstractArray{T, D}, AbstractArray{Bool, D}}} where {T, D}","page":"Methods","title":"MIRT.getindex!","text":"getindex!(y::AbstractVector, x::AbstractArray{T,D}, mask::AbstractArray{Bool,D})\n\nEquivalent to the in-place y .= x[mask] but is non-allocating.\n\nFor non-Boolean indexing, just use @views y .= A[index], per https://discourse.julialang.org/t/efficient-non-allocating-in-place-getindex-for-bitarray/42268\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.interp1-Tuple{AbstractVector{<:Real}, AbstractVector{<:Number}, Any}","page":"Methods","title":"MIRT.interp1","text":"yi = interp1(x, y, xi ; how=Gridded(Linear()), extrap=0)\n\n1D interpolation of y = f(x) at points xi\n\nIn:\n\nx::AbstractVector{<:Real}\ny::AbstractVector{<:Number}\n\nOption:\n\nhow::Interpolations.InterpolationType default Gridded(Linear())\nextrap::Any how to extrapolate, e.g., Flat(); default 0\n\nother options from Interpolations.jl are Line() Periodic() Reflect() Throw()\n\nOutput is same size as input xi\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ir_dump-Tuple{Any}","page":"Methods","title":"MIRT.ir_dump","text":"ir_dump(x::Any ; io::IO = stdout)\nir_dump(io::IO, x::Any)\n\nShow all the fields of a structure or NamedTuple more nicely than dump() does\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ir_load_brainweb_t1_256-Tuple{}","page":"Methods","title":"MIRT.ir_load_brainweb_t1_256","text":"data = ir_load_brainweb_t1_256()\n\nLoad brainweb T1-weighted MRI slice of size 256 × 256.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ir_mri_coil_compress-Tuple{AbstractArray{<:Number}}","page":"Methods","title":"MIRT.ir_mri_coil_compress","text":"(odata, σ, Vr) = ir_mri_coil_compress(idata ; ncoil)\n\nMRI coil compression via PCA. Given multiple MRI surface coil images (idata), use SVD/PCA to find a smaller number of virtual coil images (odata).\n\nIn:\n\nidata [(N) n_in]: noisy complex images (2D or 3D) for each coil\n\nOption:\n\nncoil Desired # of virtual coils (default: 1)\n\nOut:\n\nodata [(N) ncoil]: virtual coil images\nσ     [n_in]: singular values.\nVr    [n_in, ncoil]: compression matrix for reducing other data.\n\ntodo: currently ignores noise correlations\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ir_mri_kspace_ga_radial-Tuple{}","page":"Methods","title":"MIRT.ir_mri_kspace_ga_radial","text":"kspace = ir_mri_kspace_ga_radial(; Nro=?, Nspoke=?, ...)\n\nGenerate k-space sampling pattern for \"golden angle\" radial sampling.\n\noption\n\nNro:Int number of samples in each readout/spoke, default 256\nNspoke::Int number of spokes, default 1\nstart::Real first angle in series [radians], default π/2\nangle::Real angular spacing [radians], default GA\ndelta_ro::Real readout spacing, default 1/Nro\nshift::Real shift due to gradient delays, default 0\nradial sample locations are ir * delta_ro\nwhere ir = [-(Nro/2 - 1):1:Nro/2] + shift\n\nout\n\nkspace [Nro Nspoke 2] (Float32)\n\nkx and ky k-space locations for Nspoke*Nro samples in interval (-0.5 0.5] for default shift, delta_ro so default units are \"cycles / sample\"\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ir_mri_sensemap_sim-Tuple{Symbol}","page":"Methods","title":"MIRT.ir_mri_sensemap_sim","text":"(smap,info) = ir_mri_sensemap_sim( :all ; kwargs)\n\nLike ir_mri_sensemap_sim but also returns info with data for all coils, mainly for testing and plotting.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ir_mri_sensemap_sim-Tuple{Vector{Tuple{Int64, Int64}}}","page":"Methods","title":"MIRT.ir_mri_sensemap_sim","text":"(smap,info) = ir_mri_sensemap_sim( ir_ic_pair ; kwargs)\n\nLike ir_mri_sensemap_sim but also returns info with data for specific coils where ir_ic_pair::Vector{Tuple{Int,Int}}. (Usually used internally only.)\n\ninfo::NamedTuple geometry information for plots\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ir_mri_sensemap_sim-Tuple{}","page":"Methods","title":"MIRT.ir_mri_sensemap_sim","text":"smap = ir_mri_sensemap_sim(...)\n\nSimulate 2D or 3D sensitivity maps for sensitivity-encoded MRI based on grivich:00:tmf.\n\nThis code makes maps for multiple coils, but does not model coupling between coils, so most likely it is an approximation at best.\n\noption\n\ndims::Dims image size; default (64, 64)\ndx::Real pixel/voxel dimension; default: 3\ndy::Real pixel/voxel dimension; default: dx\ndz::Real \"\"\nncoil::Int # of coils total; default 4\nnring::Int # of rings of coils; default 1\nrcoil::Real coil radius; default dx * nx / 2 * 0.50\ndz_coil ring spacing in z; default nz*dz/nring\n(3D geometry is a cylinder)\ncoil_distance::Real distance of coil center from isocenter\nfor central ring of coils as a multiple of FOVx,\nwhere FOVx=nx*dx; default 1.2\norbit::Real default 360 [degrees]\norbit_start::AbstractVector{<:Real} = fill(0, nring) [degrees]\nscale::Symbol\n:none (default)\nssos_center make SSoS of center = 1\n\nout\n\nsmap [dims ncoil] simulated sensitivity maps (complex!)\n\nAll length parameters must have same units (e.g., mm or cm)\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ir_mri_sensemap_sim_do-NTuple{14, Any}","page":"Methods","title":"MIRT.ir_mri_sensemap_sim_do","text":"(smap, info) = ir_mri_sensemap_sim_do()\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ir_mri_smap1-NTuple{4, Any}","page":"Methods","title":"MIRT.ir_mri_smap1","text":"ir_mri_smap1()\n\nBased on grivich:00:tmf for a circular coil in \"x-y plane\" of radius \"a\"\n\nNote that coil x-y plane is not same as object x-y plane!\n\nReturns (i,j,k) components of B vector for each (x,y,z) location.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ir_mri_smap_r-Tuple{Any, Any}","page":"Methods","title":"MIRT.ir_mri_smap_r","text":"ir_mri_smap_r(r, z)\n\nFunction for testing near 0.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.jinc-Tuple{Real}","page":"Methods","title":"MIRT.jinc","text":"jinc(x)\n\nReturn jinc(x) = J1(pi*x)/(2x), where J1 is a Bessel function of the first kind.\n\nUnits of x are typically cycles/m.\n\nReturn type is promote_type(typeof(x), Float32).\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.line_search_mm-Tuple","page":"Methods","title":"MIRT.line_search_mm","text":"α = line_search_mm(args...; opt, fun, kwargs...)\n\nLine-search based on majorize-minimize (MM) approach. This is a wrapper around the iterator LineSearchMM. See its constructors for args and other kwargs.\n\noption\n\nfun(state) User-defined function to be evaluated with the state initially and then after each iteration.\nout::Union{Nothing,Vector{Any}} = nothing optional place to store result of fun for iterates 0,…,ninner:  (All missing by default.) This is aVector{Any}of lengthninner+1`.\n\noutput\n\nα final iterate\n\nThis function mutates the optional arguments out and work.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.make_dot_curvf-Union{Tuple{Tw}, Tuple{Tx}, Tuple{Function, AbstractArray{Tx}}, Tuple{Function, AbstractArray{Tx}, Type{<:Number}}} where {Tx<:Number, Tw<:Number}","page":"Methods","title":"MIRT.make_dot_curvf","text":"make_dot_curvf(curv::Function, [x, Tf::Type; w = similar(x)])\n\nMake a function with arguments (v, x) that computes the dot product between abs2.(v) and curv(x) where curv(x) is a curvature function associated with a quadratic majorizer for some real-valued cost function f(x), evaluated at array x, typically for use in a line-search method.\n\nFor a single-argument gradient function curv(x), this returns the version equivalent to (v, x) -> dot(abs2.(v), curv(x)). This version will be allocating, unless curv has its own internal workspace due to a closure. This version expects only the argument curv.\nFor a two-argument mutating gradient function curv!(w, x), this returns a function equivalent to (v, x) -> dot(abs2.(v), curv!(w, x)) using the keyword argument w as the work array.\nIf curv is simply a real number (a Lipschitz constant), possibly with units, then this returns the function (v, x) -> curv * sum(abs2, v).\n\nIf f(x) maps an Array x of elements with units Ux into real numbers with units Uf, then its curvature has units Uf/Ux^2. Those units are relevant to defining the work array w.\n\nin\n\ncurv::Function see above\nx an array whose size and eltype is used to allocate w\n\noption\n\nTf::Type = typeof(one(eltype(x))) Specify eltype of function f(x), defaulting to unitless.\nw = similar(x,  typeof(oneunit(Tf) / oneunit(eltype(x))^2)) work space for gradient calculation, with appropriate units (if needed).\n\nout\n\n(v, x) -> dot(abs2.(v), curv([w,] x)) or equivalent.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.make_dot_gradf-Union{Tuple{Tw}, Tuple{Tx}, Tuple{Function, AbstractArray{Tx}}, Tuple{Function, AbstractArray{Tx}, Type{<:Number}}} where {Tx<:Number, Tw<:Number}","page":"Methods","title":"MIRT.make_dot_gradf","text":"make_dot_gradf(grad::Function, [x, Tf::Type; w = similar(x)])\n\nMake a function with arguments (v, x) that computes the dot product between an array v and the gradient grad(x) of some real-valued cost function f(x), evaluated at array x, typically for use in a line-search method.\n\nFor a single-argument gradient function grad(x), this returns the version (v, x) -> dot(v, grad(x)). This version will be allocating, unless grad has its own internal workspace due to a closure. This version expects only the argument grad.\nFor a two-argument mutating gradient function grad!(w, x), this returns a function (v, x) -> dot(v, grad!(w, x))  using the keyword argument w as the work array.\n\nIf f(x) maps an Array x of elements with units Ux into real numbers with units Uf, then the gradient ∇f has units Uf/Ux. Those units are relevant to defining the work array w.\n\nin\n\ngrad::Function see above\nx an array whose size and eltype is used to allocate w\nTf::Type = typeof(one(eltype(x))) Specify eltype of function f(x), defaulting to unitless.\n\noption\n\nw = similar(x, typeof(oneunit(Tf) / oneunit(eltype(x)))) work space for gradient calculation, with appropriate units (if needed).\n\nout\n\n(v, x) -> dot(v, grad([w,] x)) or equivalent.\n\nExample. Consider the cost function f(x) = sum(sin.(x)) that has gradient g(x) = cos.(x). The simple way here is make_dot_gradf(g), which will return the function (v, x) = dot(v, g(x)) === dot(v, cos.(x)). That will work fine, but the cos.(x) step will be allocating. A better way (for repeated use) is\n\nfunction g!(work, x)\n   @. work = cos(x) # mutating\n   return work\nend\n\nThen make_dot_gradf(g!, x) will return a function (v,x) that does not allocate (except when first generated via a closure). For this particular example, an even better approach is to directly define dot_gradf(v,x) = sum(vx -> vx[1]*cos(vx[2]), zip(v,x)), but make_dot_gradf is here for more general cases.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.map_many-Tuple{Function, AbstractArray, Tuple{Vararg{Int64, N}} where N}","page":"Methods","title":"MIRT.map_many","text":"y = map_many(fun::Function, x::AbstractArray{<:Any}, idim::Dims)\n\nApply a function fun to leading slices of input x; cousin of mapslices\n\nin\n\nfun::Function maps input of size idim to output of some size odim\nx [idim ldim]\n\nout\n\ny [odim ldim]\n\nExample: if fun maps array of size (1,2) to array of size (3,4,5) and if input x has size (1,2,7,8) then output y will have size (3,4,5,7,8) where y[:,:,:,i,j] = fun(x[:,:,i,j])\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.mask_or-Tuple{AbstractMatrix{Bool}}","page":"Methods","title":"MIRT.mask_or","text":"mask_or(mask)\n\ncompress 3D mask to 2D by logical or along z direction\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.mask_outline-Tuple{AbstractMatrix{Bool}}","page":"Methods","title":"MIRT.mask_outline","text":"mask_outline(mask)\n\nreturn outer boundary of 2D mask (or mask_or for 3D)\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.maskit-Tuple{AbstractArray{<:Number}, AbstractArray{Bool}}","page":"Methods","title":"MIRT.maskit","text":"maskit(x::AbstractArray{<:Number})\n\nopposite of embed\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.max_percent_diff-Tuple{Any, Any}","page":"Methods","title":"MIRT.max_percent_diff","text":"max_percent_diff(s1, s2, [options])\n\nCompute the \"maximum percent difference\" between two signals: s1, s2.\n\nDefault is to normalize by maximum(abs, s1).\n\noptions\n\nmaxboth::Bool = false use max of both arguments to normalize\nnormalize::Bool = false normalize each before comparing\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.mri_kspace_spiral-Tuple{}","page":"Methods","title":"MIRT.mri_kspace_spiral","text":"kspace, omega, gradxy = mri_kspace_spiral( [options] )\n\nMake k-space spiral trajectory based on GE 3T scanner constraints\n\nOption:\n\nN dimension of reconstructed image\nNt # of time points\nfov field of view in cm\ndt time sampling interval out; default 5e-6 sec\ngamp::Real design gradient amplitude max, G/cm; default 2.2\ngslew::Int design slew rate, mT/m/ms; default 180\n\nOut:\n\nkspace [Nt,2] kspace trajectory [kx ky] in cycles/cm, NO: cycles/FOV\nomega [Nt,2] \"\" in radians\ngradxy [Nt 2] gradient waveforms in (units?)\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.mri_trajectory-Union{Tuple{}, Tuple{D}} where D","page":"Methods","title":"MIRT.mri_trajectory","text":"kspace, omega, wi = mri_trajectory( ; ktype, N, fov, arg_wi, kwargs...)\n\nGenerate kspace trajectory samples and density compensation functions.\n\noption\n\nktype::Symbol k-space trajectory type; default :radial\nN::Dims target image size; default (32,30)\nfov field of view in x and y (and z); default (250,250) mm\narg_wi options to pass to ir_mri_density_comp - not yet done\nkwargs options for the specific trajectory\n\nout\n\nkspace [Nk 2|3] kspace samples in units 1/fov\nomega [Nk 2|3] trajectory samples over [-π,π)\nwi [Nk 1] (optional) density compensation factors\n\ntrajectory types:\n\n:cartesian\n:radial\n:cart_y_2\n:random\n:half8\n:epi_sin\n:spiral0 :spiral1 :spiral3\n:rosette3\n:epi_under\n:gads (emulate golden-angle data sharing per winkelmann:07:aor)\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.mri_trajectory_gads-Union{Tuple{Nring}, Tuple{Tuple{Vararg{Int64, N}} where N, Any}} where Nring","page":"Methods","title":"MIRT.mri_trajectory_gads","text":"omega, wi = mri_trajectory_gads(N, fov ; ...)\n\nEmulate 2D golden angle radial sampling with data sharing\n\noption\n\nNro # of samples in each readout/spoke\nshift shift along read-out due to gradient delays (stress)\nkmax_frac fractions of maximum krad (0.5) for rings (annuli)\nunder under-sampling factor for each annulus\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.mri_trajectory_radial-Tuple{Tuple{Vararg{Int64, N}} where N, Any}","page":"Methods","title":"MIRT.mri_trajectory_radial","text":"mri_trajectory_radial()\n\noption\n\nna_nr default ensures proper sampling at edge of k-space\nna angular spokes; default: na_nr * nr\nnr radial samples per spoke\nir default: 0:nr\n\ntodo: generalize to 3D using barger:02:trc\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.mri_trajectory_rosette3-Tuple{Any, Any}","page":"Methods","title":"MIRT.mri_trajectory_rosette3","text":"mri_trajectory_rosette3(N, fov ; ...)\n\n3d rosette, with default parameters from bucholz:08:miw\n\noption\n\nomax maximum omega\nnt time samples (65.536 ms for 4 usec dt)\ndt time sample spacing (4 usec)\nti time samples\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ncg-Tuple{AbstractVector, AbstractVector{<:Function}, AbstractVector{<:Function}, AbstractArray{<:Number}}","page":"Methods","title":"MIRT.ncg","text":"(x,out) = ncg(B, gradf, curvf, x0 ; ...)\n\nNonlinear preconditioned conjugate gradient algorithm to minimize a general \"inverse problem\" cost function of the form Psi(x) = sum_j=1^J f_j(B_j x) where each function f_j(v) has a quadratic majorizer of the form\n\nq_j(vu) = f_j(u) + nabla f_j(u) (v - u) + 12 v - u^2_C_j(u)\n\nwhere C_j(u) is diagonal matrix of curvatures. (It suffices for each f_j to have a Lipschitz smooth gradient.)\n\nThis CG method uses a majorize-minimize (MM) line search.\n\nin\n\nB vector of J blocks B_1B_J\ngradf vector of J functions return gradients of f_1f_J\ncurvf vector of J functions z -> curv(z) that return a scalar or a vector of curvature values for each element of z\nx0 initial guess; need length(x) == size(B[j],2) for j=1J\n\nUsually x0 is a Vector but it can be an Array if each B_j is a linear operator (e.g., LinearMapAO) of suitable \"dimensions\".\n\noption\n\nniter # number of outer iterations; default 50\nninner # number of inner iterations of MM line search; default 5\nP # preconditioner; default I\nbetahow \"beta\" method for the search direction; default :dai_yuan\nfun User-defined function to be evaluated with two arguments (x,iter).\nIt is evaluated at (x0,0) and then after each iteration.\n\noutput\n\nx final iterate\nout [niter+1] (fun(x0,0), fun(x1,1), ..., fun(x_niter,niter))\n(all 0 by default). This is an array of length niter+1\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ncg-Tuple{Function, Function, AbstractArray{<:Number}}","page":"Methods","title":"MIRT.ncg","text":"(x,out) = ncg(grad, curv, x0, ...)\n\nSpecial case of ncg (nonlinear CG) for minimizing a cost function whose gradient is grad(x) and that has a quadratic majorizer with diagonal Hessian given by curv(x). Typically curv = (x) -> L where L is the Lipschitz constant of grad.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.nufft_eltype-Tuple{Type{<:Integer}}","page":"Methods","title":"MIRT.nufft_eltype","text":"nufft_eltype(::Type)\n\nensure plan_nfft eltype is Float32 or Float64\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.nufft_errors-Tuple{}","page":"Methods","title":"MIRT.nufft_errors","text":"w, errs = nufft_errors( ; M=401, w=?, N=513, n_shift=0, ...)\n\nCompute NUFFT approximation errors (for signal of length N of unit norm), for given digital frequency values w, i.e., Ω. Default w is range(0, 2π/N, M).\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.nufft_init-Tuple{AbstractArray{<:Real}, Int64}","page":"Methods","title":"MIRT.nufft_init","text":"p = nufft_init(w, N ; nfft_m=4, nfft_sigma=2.0, pi_error=true, n_shift=0)\n\nSetup 1D NUFFT, for computing fast O(N log N) approximation to\n\nXm = sum_n=0^N-1 xn exp(-i wm (n - n_shift)) m=1M\n\nin\n\nw::AbstractArray{<:Real} [M] frequency locations (aka Ω, units radians/sample)\neltype(w) determines the plan_nfft type; so to save memory use Float32!\nsize(w) determines odim for A if operator=true\nN::Int signal length\n\noption\n\nnfft_m::Int see NFFT.jl documentation; default 4\nnfft_sigma::Real \"\", default 2.0\nn_shift::Real often is N/2; default 0\npi_error::Bool throw error if w  π, default true\nSet to false only if you are very sure of what you are doing!\ndo_many::Bool  support extended inputs via map_many? default true\noperator::Bool=true set to false to make A an LinearMapAM\n\nout\n\np NamedTuple\n\n(nufft = x -> nufft(x), adjoint = y -> nufft_adj(y), A::LinearMapAO)\n\nThe default settings are such that for a 1D signal of length N=512, the worst-case error is below 1e-5 which is probably adequate for typical medical imaging applications. To verify this statement, run nufft_plot1() and see plot.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.nufft_init-Union{Tuple{D}, Tuple{AbstractArray{<:Real}, Tuple{Vararg{Int64, D}}}} where D","page":"Methods","title":"MIRT.nufft_init","text":"p = nufft_init(w, N ; nfft_m=4, nfft_sigma=2.0, pi_error=true, n_shift=?)\n\nSetup multi-dimensional NUFFT, for computing fast O(N log N) approximation to\n\nXm = sum_n=0^N-1 xn exp(-i wm (n - n_shift)) m=1M\n\nin\n\nw::AbstractArray{<:Real} [M,D] frequency locations (aka Ω, units radians/sample)\neltype(w) determines the plan_nfft type; so to save memory use Float32!\nsize(w)[1:(end-1)] determines odim if operator=true\nN::Dims{D} signal dimensions\n\noption\n\nnfft_m::Int see NFFT.jl documentation; default 4\nnfft_sigma::Real \"\", default 2.0\nn_shift::AbstractVector{<:Real} (D) often is N/2; default zeros(D)\npi_error::Bool throw error if w  π, default true\nSet to false only if you are very sure of what you are doing!\ndo_many::Bool support extended inputs via map_many? default true\noperator::Bool=true set to false to make A a LinearMapAM\n\nThe default do_many option is designed for parallel MRI where the k-space sampling pattern applies to every coil. It may also be useful for dynamic MRI with repeated sampling patterns. The coil and/or time dimensions must come after the spatial dimensions.\n\nout\n\np NamedTuple with fields   nufft = x -> nufft(x), adjoint = y -> nufft_adj(y), A=LinearMapAO   (Using operator=true allows the LinearMapAO to support do_many.)\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.nufft_typer-Union{Tuple{T}, Tuple{Type{T}, T}} where T","page":"Methods","title":"MIRT.nufft_typer","text":"nufft_typer(T::Type, x::AbstractArray{<:Real} ; warn::Bool=true)\n\ntype conversion wrapper for nfft()\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ogm_ls-Tuple{AbstractVector, AbstractVector{<:Function}, AbstractVector{<:Function}, AbstractArray{<:Number}}","page":"Methods","title":"MIRT.ogm_ls","text":"(x,out) = ogm_ls(B, gradf, curvf, x0; niter=?, ninner=?, fun=?)\n\nOGM with a line search Drori&Taylor to minimize a general \"inverse problem\" cost function of the form Psi(x) = sum_j=1^J f_j(B_j x) where each function f_j(v) has a quadratic majorizer of the form\n\nq_j(vu) = f_j(u) + nabla f_j(u) (v - u) + 12 v - u^2_C_j(u)\n\nwhere C_j(u) is diagonal matrix of curvatures. (It suffices for each f_j to have a Lipschitz smooth gradient.)\n\nThis OGM method uses a majorize-minimize (MM) line search.\n\nin\n\nB vector of J blocks B_1B_J\ngradf vector of J functions return gradients of f_1f_J\ncurvf vector of J functions z -> curv(z) that return a scalar or a vector of curvature values for each element of z\nx0 initial guess; need length(x) == size(B[j],2) for j=1J\n\noption\n\nniter # number of outer iterations; default 50\nninner # number of inner iterations of MM line search; default 5\nfun User-defined function to be evaluated with two arguments (x,iter).\nIt is evaluated at (x0,0) and then after each iteration.\n\noutput\n\nx final iterate\nout (niter+1) (fun(x0,0), fun(x1,1), ..., fun(x_niter,niter))\n(all 0 by default). This is a vector of length niter+1.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.ogm_ls-Tuple{Function, Function, AbstractVector{<:Number}}","page":"Methods","title":"MIRT.ogm_ls","text":"(x,out) = ogm_ls(grad, curv, x0, ...)\n\nSpecial case of ogm_ls (OGM with line search) for minimizing a cost function whose gradient is grad(x) and that has a quadratic majorizer with diagonal Hessian given by curv(x). Typically curv = (x) -> L where L is the Lipschitz constant of grad.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.pogm_restart-Tuple{Any, Function, Function, Real}","page":"Methods","title":"MIRT.pogm_restart","text":"x, out = pogm_restart(x0, Fcost, f_grad, f_L ;\nf_mu=0, mom=:pogm, restart=:gr, restart_cutoff=0.,\nbsig=1, niter=10, g_prox=(z,c)->z, fun=...)\n\nIterative proximal algorithms (PGM=ISTA, FPGM=FISTA, POGM) with restart.\n\nin\n\nx0 initial guess\nFcost function for computing the cost function value F(x)\n(needed only if restart === :fr)\nf_grad function for computing the gradient of f(x)\nf_L Lipschitz constant of the gradient of f(x)\n\noption\n\nf_mu strong convexity parameter of f(x); default 0.\nif f_mu > 0, (alpha beta_k gamma_k) is chosen by Table 1 in [KF18]\ng_prox function g_prox(z,c) for the proximal operator for g(x)\ng_prox(z,c) computes argmin_x 12 z-x^2 + c  g(x)\nmom momentum option\n:pogm POGM (fastest); default!\n:fpgm (FISTA), gamma_k = 0\n:pgm PGM (ISTA), beta_k = gamma_k = 0\nrestart restart option\n:gr gradient restart; default!\n:fr function restart\n:none no restart\nrestart_cutoff for :gr restart if cos(angle) < this; default 0.\nbsig gradient \"gamma\" decrease option (value within [0 1]); default 1\nsee barsigma in [KF18]\nniter number of iterations; default 10\nfun function(iter, xk, yk, is_restart) user-defined function evaluated each iter with secondary xk, primary yk, and boolean is_restart indicating whether this iteration was a restart\n\nout\n\nx final iterate\nfor PGM (ISTA): x_N = y_N\nfor FPGM (FISTA): primary iterate y_N\nfor POGM: secondary iterate x_N, see [KF18]\nout [fun(0, x0, x0, false), fun(1, x1, y1, is_restart), ...] array of length [niter+1]\n\nOptimization Problem: Nonsmooth Composite Convex Minimization\n\nargmin_x F(x)  F(x) = f(x) + g(x))\nf(x) smooth convex function\ng(x) convex function, possibly nonsmooth and \"proximal-friendly\" [CP11]\n\nOptimization Algorithms:\n\nAccelerated First-order Algorithms when g(x) = 0 [KF18] iterate as below for given coefficients (alpha beta_k gamma_k)\n\nFor k = 0,1,...\ny_k+1 = x_k - alpha  f(x_k) : gradient update\nx_k+1 = y_k+1 + beta_k  (y_k+1 - y_k) + gamma_k  (y_k+1 - x_k) : momentum update\n\nProximal versions of the above for g(x) neq 0 are in the below references, and use the proximal operator prox_g(z) = argmin_x 12z-x^2 + g(x).\n\nProximal Gradient method (PGM or ISTA) - beta_k = gamma_k = 0. [BT09]\nFast Proximal Gradient Method (FPGM or FISTA) - gamma_k = 0. [BT09]\nProximal Optimized Gradient Method (POGM) - [THG15]\nFPGM(FISTA) with Restart - [OC15]\nPOGM with Restart - [KF18]\n\nreferences\n\n[CP11] P. L. Combettes, J. C. Pesquet,\n\n\"Proximal splitting methods in signal processing,\"  Fixed-Point Algorithms for Inverse Problems in Science and Engineering,  Springer, Optimization and Its Applications, 2011.\n\n[KF18] D. Kim, J.A. Fessler,\n\n\"Adaptive restart of the optimized gradient method for convex optimization,\" 2018  Arxiv:1703.04641,  [http://doi.org/10.1007/s10957-018-1287-4]\n\n[BT09] A. Beck, M. Teboulle:\n\n\"A fast iterative shrinkage-thresholding algorithm for linear inverse problems,\"  SIAM J. Imaging Sci., 2009.\n\n[THG15] A.B. Taylor, J.M. Hendrickx, F. Glineur,\n\n\"Exact worst-case performance of first-order algorithms  for composite convex optimization,\" Arxiv:1512.07516, 2015,  SIAM J. Opt. 2017  [http://doi.org/10.1137/16m108104x]\n\nCopyright 2017-3-31, Donghwan Kim and Jeff Fessler, University of Michigan 2018-08-13 Julia 0.7.0 2019-02-24 interface redesign\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.poweriter-Tuple{Any}","page":"Methods","title":"MIRT.poweriter","text":"v1,σ1 = poweriter(A; niter=?, ...)\n\nDetermine first right singular vector v1 and first singular value σ1 of A by applying power iteration to A'A\n\nin\n\nA M × N matrix\n\noption\n\nniter default 200\nx0 initial guess of v1\ntol stopping tolerance for s1, default 1e-6\nchat::Bool verbose? default false\n\nout\n\nv1 [N] principal right singular vector\nσ1 spectral norm of A\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.rect-Tuple{Real}","page":"Methods","title":"MIRT.rect","text":"rect(x::Real)\n\nUnit width rect function. Potential problem? Bring up with fess.\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.reverser-Tuple{AbstractArray, AbstractVector{<:Int64}}","page":"Methods","title":"MIRT.reverser","text":"y = reverser(x, dims)\n\nreverse array along specified dimensions (or all if unspecified)\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.rmsd100-Tuple{AbstractArray{<:Number}, AbstractArray{<:Number}}","page":"Methods","title":"MIRT.rmsd100","text":"rmsd = rmsd100(x, y ; mask)\n\nCompute 100 * RMSD (root mean squared difference) between x and y within domain mask.\n\nin\n\nx : array\ny : another array of same size\n\noption\n\nmask::Array{Bool} : domain over which to compute the RMSE; default trues(size(x))\n\nout\n\nrmsd : rmsd of x vs y within mask in %\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.rotate2d-Tuple{Any, Any, Any}","page":"Methods","title":"MIRT.rotate2d","text":"(xr,yr) = rotate2d(x, y, theta)\n\n2D rotation\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.snr2sigma-Tuple{Any, AbstractArray{<:Complex}}","page":"Methods","title":"MIRT.snr2sigma","text":"snr2sigma(db, yb)\n\nConvert SNR in dB to noise σ for complex gaussian noise. No sqrt(2) factors is needed here because randn(Complex{Float}) already accounts for that. (See randn documentation.)\n\n\n\n\n\n","category":"method"},{"location":"methods/#MIRT.@shows-Tuple{Any}","page":"Methods","title":"MIRT.@shows","text":"@shows expr\n\nShow the type and size of an expression expr (typically a variable).\n\nMore concise output than @show and typically this is all that is needed when debugging code.\n\n\n\n\n\n","category":"macro"},{"location":"#MIRT:-The-Michigan-Image-Reconstruction-Toolbox","page":"Home","title":"MIRT: The Michigan Image Reconstruction Toolbox","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"MIRT.jl is a collection of Julia functions for performing image reconstruction and solving related inverse problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"It is very much still under construction, although there are already enough tools to solve useful problems like compressed sensing MRI reconstruction. Trying the demos is a good way to get started.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The documentation is even more still under construction.","category":"page"},{"location":"","page":"Home","title":"Home","text":"More complete examples are at JuliaImageRecon; see Examples there.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"EditURL = \"../../../lit/examples/3-ls-mm.jl\"","category":"page"},{"location":"generated/examples/3-ls-mm/#3-ls-mm","page":"Line search MM","title":"Line search MM","text":"","category":"section"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Examples illustrating the line-search method based on majorize-minimize (MM) principles in the Julia package MIRT. This method is probably most useful for algorithm developers.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"This page comes from a single Julia file: 3-ls-mm.jl.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"You can access the source code for such Julia documentation using the 'Edit on GitHub' link in the top right. You can view the corresponding notebook in nbviewer here: 3-ls-mm.ipynb, or open it in binder here: 3-ls-mm.ipynb.","category":"page"},{"location":"generated/examples/3-ls-mm/#Setup","page":"Line search MM","title":"Setup","text":"","category":"section"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Packages needed here.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"using Plots; default(markerstrokecolor = :auto, label=\"\")\nusing MIRTjim: prompt\nusing MIRT: line_search_mm, LineSearchMMWork\nusing LineSearches: BackTracking, HagerZhang, MoreThuente\nusing LinearAlgebra: norm, dot\nusing Random: seed!; seed!(0)\nusing BenchmarkTools: @btime, @benchmark\nusing InteractiveUtils: versioninfo","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"The following line is helpful when running this file as a script; this way it will prompt user to hit a key after each figure is displayed.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"isinteractive() && prompt(:prompt);\nnothing #hide","category":"page"},{"location":"generated/examples/3-ls-mm/#Theory","page":"Line search MM","title":"Theory","text":"","category":"section"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Many methods for solving inverse problems involve optimization problems of the form","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"hatx = argmin_x  mathbbF^N f(x)\nqquad\nf(x) = sum_j=1^J f_j(B_j x)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"where mathbbF denotes the field of real or complex numbers, matrix B_j has size M_j  N, and f_j  mathbbF^M_j  mathbbR.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"One could apply general-purpose optimization methods here, like those in Optim.jl, but often we can obtain faster results by exploiting the specific (yet still fairly general) structure, particularly when the problem dimension N is large.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Many algorithms for solving such problems require an inner 1D optimization problem called a line search of the form","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"α_* = argmin_α  mathbbR h(α)\nqquad\nh(α) = f(x + α d)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"for some search direction d. There are general purpose line search algorithms in LineSearches.jl, but here we focus on the specific form of f given above.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"For that form we see that we have the special structure","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"h(α) = sum_j=1^J f_j(u_j + α v_j)\nqquad\nu_j = B_j x\nquad\nv_j = B_j d","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Here we focus further on the case where each function f_j() has a quadratic majorizer of the form","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"f_j(x)  q_j(xz) = f_j(z) + textreal( f_j(z) x - z )\n+ frac12 (x - z) D_j(z) (x - z)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"where D_j(z) is a positive semidefinite matrix that typically is diagonal. Often it is a constant times the identity matrix, e.g., a Lipschitz constant for f_j, but often there are sharper majorizers.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Such quadratic majorizers induce a quadratic majorizer for h(α) as well:","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"h(α)  q(α α_t) =\nsum_j=1^J q_j(u_j + α v_j u_j + α_t v_j)\n= h(α_t) + c_1(α_t) (α - α_t)\n+ frac12 c_2(α_t) (α - α_t)^2","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"where","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"c_1(α_t) = sum_j=1^J textreal( f_j(u_j + α_t v_j) v_j )\nqquad\nc_2(α_t) = sum_j=1^J v_j D_j(u_j + α_t v_j) v_j","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"The line_search_mm function in this package uses this quadratic majorizer to update α using the iteration","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"α_t+1\n= argmin_α q(αα_t)\n= α_t - c_1(α_t)  c_2(α_t)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Being an MM algorithm, it is guaranteed to decrease h(α) every update. For an early exposition of this approach, see Fessler & Booth, 1999.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"From the above derivation, the main ingredients needed are functions for computing the dot products  f_j(u_j + α_t v_j) v_j  and v_j D_j(u_j + α_t v_j) v_j.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"The line_search_mm function can construct such functions given input gradient functions f_1f_J and curvature functions ω_1ω_J where D_j(z) = textDiag(ω_j(z)).","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Alternatively, the user can provide functions for computing the dot products.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"All of this is best illustrated by an example.","category":"page"},{"location":"generated/examples/3-ls-mm/#Smooth-LASSO-problem","page":"Line search MM","title":"Smooth LASSO problem","text":"","category":"section"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"The usual LASSO optimization problem uses the cost function","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"f(x) = frac12  A x - y _2^2 + β R(x)\nqquad\nR(x) =  x _1 = sum_n=1^N x_n = 1 textabs(x)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"The 1-norm is just a relaxation of the 0-norm so here we further \"relax\" it by considering the \"corner rounded\" version using the Fair potential function","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"R(x) = sum_n=1^N ψ(x_n) = 1 ψ(x)\nqquad\nψ(z) = δ^2 zδ - log(1 + zδ)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"for a small value of δ.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"The derivative of this potential function is dotψ(z) = z  (1 + z  δ) and Huber's curvature ω_ψ(z) = 1  (1 + z  δ) provides a suitable majorizer.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"This smooth LASSO cost function has the general form above with J=2, B_1 = A, B_2 = I, f_1(u) = frac12  u - y _2^2 f_2(u) = β 1 ψ(u) for which f_1(u) = u - y f_2(u) = β ψ(u) and ^2 f_1(u) = I ^2 f_2(u) succeq β  textdiag(ω_ψ(u))","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Set up an example and plot h(α).","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Fair potential, its derivative and Huber weighting function:","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"function fair_pot()\n    fpot(z,δ) = δ^2 * (abs(z/δ) - log(1 + abs(z/δ)))\n    dpot(z,δ) = z / (1 + abs(z/δ))\n    wpot(z,δ) = 1 / (1 + abs(z/δ))\n    return fpot, dpot, wpot\nend;\nnothing #hide","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Data, cost function and gradients for smooth LASSO problem:","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"M, N = 1000, 2000\nA = randn(M,N)\nx0 = randn(N) .* (rand(N) .< 0.4) # sparse vector\ny = A * x0 + 0.001 * randn(M)\nβ = 95\nδ = 0.1\nfpot, dpot, wpot = Base.Fix2.(fair_pot(), δ)\n\nf(x) = 0.5 * norm(A * x - y)^2 + β * sum(fpot, x)\n∇f(x) = A' * (A * x - y) + β * dpot.(x)\nx = randn(N) # random point\nd = -∇f(x)/M # some search direction\nh(α) = f(x + α * d)\ndh(α) = d' * ∇f(x + α * d)\npa = plot(h, xlabel=\"α\", ylabel=\"h(α)\", xlims=(-1, 2))","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Apply MM-based line search: simple version. The key inputs are the gradient and curvature functions:","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"gradf = [\n    u -> u - y, # ∇f₁ for data-fit term\n    u -> β * dpot.(u), # ∇f₂ for regularizer\n]\ncurvf = [\n    1, # curvature for data-fit term\n    u -> β * wpot.(u), # Huber curvature for regularizer\n]\n\nuu = [A * x, x] # [u₁ u₂]\nvv = [A * d, d] # [v₁ v₂]\nfun(state) = state.α # log this\nninner = 7\nout = Vector{Any}(undef, ninner+1)\nα0 = 0\nαstar = line_search_mm(gradf, curvf, uu, vv; ninner, out, fun, α0)\nhmin = h(αstar)\nscatter!([αstar], [hmin], marker=:star, color=:red)\nscatter!([α0], [h(α0)], marker=:circle, color=:green)\nps = plot(0:ninner, out, marker=:circle, xlabel=\"iteration\", ylabel=\"α\",\n    color = :green)\npd = plot(0:ninner, abs.(dh.(out)), marker=:diamond,\n    yaxis = :log, color=:red,\n    xlabel=\"iteration\", ylabel=\"|dh(α)|\")\npu = plot(1:ninner, log10.(max.(abs.(diff(out)), 1e-16)), marker=:square,\n    color=:blue, xlabel=\"iteration\", ylabel=\"log10(|α_k - α_{k-1}|)\")\nplot(pa, ps, pd, pu)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Thanks to Huber's curvatures, the α_t sequence converges very quickly.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Now explore a fancier version that needs less heap memory.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"work = LineSearchMMWork(uu, vv, α0) # pre-allocate\nfunction lsmm1(gradf, curvf)\n    return line_search_mm(gradf, curvf, uu, vv;\n        ninner, out, fun, α0, work)\nend\nfunction lsmm2(dot_gradf, dot_curvf)\n    gradn = [() -> nothing, () -> nothing]\n    return line_search_mm(uu, vv, dot_gradf, dot_curvf;\n        ninner, out, fun, α0, work)\nend;\nnothing #hide","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"The let statements below are a performance trick from the Julia manual. Using Iterators.map avoids allocating arrays like z - y and does not even require any work space.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"gradz = [\n    let y=y; z -> Iterators.map(-, z, y); end, # z - y\n    let β=β, dpot=dpot; z -> Iterators.map(z -> β * dpot(z), z); end, # β * dψ.(z)\n]\ncurvz = [\n    1,\n    let β=β, wpot=wpot; z -> Iterators.map(z -> β * wpot(z), z); end, # β * ωψ.(z)\n]\n\nfunction make_grad1c()\n    w = similar(uu[1]) # work-space\n    let w=w, y=y\n        function grad1c(z)\n            @. w = z - y\n            return w\n        end\n    end\nend\n\nfunction make_grad2c()\n    w = similar(uu[2]) # work-space\n    let w=w, β=β, dpot=dpot\n        function grad2c(z)\n            @. w = β * dpot(z)\n            return w\n        end\n    end\nend\n\nfunction make_curv2c()\n    w = similar(uu[2]) # work-space\n    let w=w, β=β, wpot=wpot\n        function curv2c(z)\n            @. w = β * wpot(z) # β * ωψ.(z)\n            return w\n        end\n    end\nend\n\ngradc = [ # capture version\n    make_grad1c(), # z - y\n    make_grad2c(), # β * dψ.(z)\n]\ncurvc = [\n    1,\n    make_curv2c(), # β * ωψ.(z)\n]\n\nsum_map(f::Function, args...) = sum(Iterators.map(f, args...))\ndot_gradz = [\n    let y=y; (v,z) -> sum_map((v,z,y) -> dot(v, z - y), v, z, y); end, # v'(z - y)\n    let β=β, dpot=dpot; (v,z) -> β * sum_map((v,z) -> dot(v, dpot(z)), v, z); end, # β * (v'dψ.(z))\n]\ndot_curvz = [\n    (v,z) -> norm(v)^2,\n    let β=β, wpot=wpot; (v,z) -> β * sum_map((v,z) -> abs2(v) * wpot(z), v, z); end, # β * (abs2.(v)'ωψ.(z))\n]\n\n\na1 = lsmm1(gradf, curvf)\na1c = lsmm1(gradc, curvc)\na2 = lsmm1(gradz, curvz)\na3 = lsmm2(dot_gradz, dot_curvz)\n@assert a1 ≈ a2 ≈ a3 ≈ a1c\n\nb1 = @benchmark a1 = lsmm1($gradf, $curvf)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"bc = @benchmark a1c = lsmm1($gradc, $curvc)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"b2 = @benchmark a2 = lsmm1($gradz, $curvz)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"b3 = @benchmark a3 = lsmm2($dot_gradz, $dot_curvz)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Timing results on my Mac:","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"95 μs\n65 μs # 1c after using make_\n80 μs\n69 μs (and lowest memory)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"The versions using gradc and dot_gradz with their \"properly captured\" variables are the fastest. But all the versions here are pretty similar so even using the simplest version seems likely to be fine.","category":"page"},{"location":"generated/examples/3-ls-mm/#Compare-with-LineSearches.jl","page":"Line search MM","title":"Compare with LineSearches.jl","text":"","category":"section"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Was all this specialized effort useful? Let's compare to the general line search methods in LineSearches.jl.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"It seems that some of those methods do not allow α₀ = 0 so we use 1.0 instead. We use the default arguments for all the solvers, which means some of them might terminate before ninner iterations, giving them a potential speed advantage.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"a0 = 1.0 # α0\nhdh(α) = h(α), dh(α)\nh0 = h(0)\ndh0 = dh(0);\nfunction ls_ls(linesearch)\n    a1, fx = linesearch(h, dh, hdh, a0, h0, dh0)\n    return a1\nend;\n\nsolvers = [\n    BackTracking( ; iterations = ninner),\n    HagerZhang( ; linesearchmax = ninner),\n    MoreThuente( ; maxfev = ninner),\n]\nfor ls in solvers # check that they work properly\n    als = ls_ls(ls)\n    @assert isapprox(als, αstar; atol=1e-3)\nend;\nnothing #hide","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"bbt = @benchmark ls_ls($(solvers[1]))","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"bhz = @benchmark ls_ls($(solvers[2]))","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"bmt = @benchmark ls_ls($(solvers[3]))","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"On my Mac the timings are all much longer compared to line_search_mm:","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"840 μs BackTracking\n2.6 ms HagerZhang\n3.9 ms MoreThuente","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"This comparison illustrates the benefit of the \"special purpose\" line search.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"The fastest version seems to be BackTracking, so plot its iterates:","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"alpha_bt = zeros(ninner + 1)\nalpha_bt[1] = a0\nfor iter in 1:ninner\n    tmp = BackTracking( ; iterations = iter)\n    alpha_bt[iter+1] = ls_ls(tmp)\nend\nplot(0:ninner, alpha_bt, marker=:square, color=:blue,\n    xlabel=\"Iteration\", ylabel=\"BackTracking α\")\nplot!([0, ninner], [1,1] * αstar, color=:red)","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"Unexpectedly, BackTracking seems to terminate at the first iteration. But even just that single iteration is slower than 7 iterations of line_search_mm.","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"prompt()","category":"page"},{"location":"generated/examples/3-ls-mm/#Reproducibility","page":"Line search MM","title":"Reproducibility","text":"","category":"section"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"This page was generated with the following version of Julia:","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"using InteractiveUtils: versioninfo\nio = IOBuffer(); versioninfo(io); split(String(take!(io)), '\\n')","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"And with the following package versions","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"import Pkg; Pkg.status()","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"","category":"page"},{"location":"generated/examples/3-ls-mm/","page":"Line search MM","title":"Line search MM","text":"This page was generated using Literate.jl.","category":"page"}]
}
